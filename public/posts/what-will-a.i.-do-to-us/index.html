<!DOCTYPE html>
<html lang="en-us">
  <head>
    <title>What will A.I. do to us? | Hido</title>

    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">    
<meta name="viewport" content="width=device-width,minimum-scale=1">
<meta name="description" content="The recent developments in A.I. have been extraordinary. Starting in mid of 20th century, A.I. lived through couple of winters and had not given up. Thanks also to the development of the hardware, early 1990s the exponential growth had begun and moving on in unprecedented speed. OpenAIs GPT3 or Dall-E in natural language processing (NLP), Deepmind&rsquo;s AlphaFold or MuZero (successor of AlphaGo &amp; AlphaZero) in Reinforcement Learning, Tesla&rsquo;s Self-Driving Autopilot in Deep Learning are the developments of only the last few years.">
<meta name="generator" content="Hugo 0.92.2" />


  <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">


<link rel="stylesheet" href="/css/style.css">



<link rel="shortcut icon" href="/images/favicon.ico" type="image/x-icon" />

 
    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'G-V7JRDN5H5Y', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>







  </head>

  <body>
    <nav class="navigation">
	
		<a href="/"> <span class="arrow">←</span>Home</a>
	
	<a href="/posts">Archive</a>
	<a href="/tags">Tags</a>
	<a href="/about">About</a>

	

	
	  <a class="button" href="https://heyhido.com/index.xml">Subscribe</a>
	
</nav>


    <main class="main">
      

<section id="single">
    <h1 class="title">What will A.I. do to us?</h1>

    <div class="tip">
        <time datetime="2021-07-18 00:00:00 &#43;0000 UTC">Jul 18, 2021</time>
        <span class="split">
          ·
        </span>
        <span>
          774 words
        </span>
        <span class="split">
          ·
        </span>
        <span>
          4 minute read
        </span>
    </div>

    
    
        
  


    


    <div class="content">
      <p>The recent developments in A.I. have been extraordinary. Starting in mid of 20th century, A.I. lived through couple of winters and had not given up. Thanks also to the development of the hardware, early 1990s the exponential growth had begun and moving on in unprecedented speed. OpenAIs <a href="https://en.wikipedia.org/wiki/GPT-3" target="_blank" rel="noopener">GPT3</a> or <a href="https://openai.com/blog/dall-e/" target="_blank" rel="noopener">Dall-E</a> in natural language processing (NLP), Deepmind&rsquo;s <a href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology" target="_blank" rel="noopener">AlphaFold</a> or <a href="https://deepmind.com/blog/article/muzero-mastering-go-chess-shogi-and-atari-without-rules" target="_blank" rel="noopener">MuZero</a> (successor of <a href="https://deepmind.com/research/case-studies/alphago-the-story-so-far" target="_blank" rel="noopener">AlphaGo</a> &amp; <a href="https://deepmind.com/blog/article/alphazero-shedding-new-light-grand-games-chess-shogi-and-go" target="_blank" rel="noopener">AlphaZero</a>) in Reinforcement Learning, Tesla&rsquo;s Self-Driving <a href="https://en.wikipedia.org/wiki/Tesla_Autopilot" target="_blank" rel="noopener">Autopilot</a> in Deep Learning are the developments of only the last few years. The field is indeed growing very fast, however it is yet not the level jump we are expecting for, moving from narrow specific problem solving A.I. to general self-aware A.I. (<a href="https://en.wikipedia.org/wiki/Artificial_general_intelligence" target="_blank" rel="noopener">AGI</a>). There are many more, although not generally accepted, characteristics that we assign to AGI to evaluate it.</p>
<p>I was thinking recently about the possible risks of having a sentient, self-aware, conscious intelligence which predictably is going to be much more advanced than us, assuming that being advanced means, relative to us, cognitively more performant. I do divide the risks of A.I. into two (sequential) categories: 1) Humans use A.I. for destructive purposes (like Nukes); 2) AGI&rsquo;s self interest goes against humans (Principal-Agent dilemma).</p>
<blockquote>
<p>“We can tentatively define a superintelligence as any intellect that greatly exceeds the cognitive peformance of humans in virtually all domains of interest.”</p>
<p>Bostrom</p>
</blockquote>
<p>In recent future, with the speed of development A.I. has, it will be able to support solving problems in very efficient manner being solely goal-oriented. Narrow A.I. depends heavily on data. Without a prior guidance finding a pattern and predicting next steps upon it would be impossible. Reinforcement learning has slightly overcome the data dependency, however it has not leaped to the next dimension. Main issue with the data dependency is that the data usually comes from humans, us. Thus any cognitive bias we have, including any ethical dilemmas, is fed to the A.I. as an extension of ours. Self-driving cars, self-controlling combat drone technology, and many other implementations of A.I. signify the <a href="https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence" target="_blank" rel="noopener">ethical challenges</a> we face already today.</p>
<p>When it comes to ethics of artificial intelligence, we should first understand the meaning of ethics here. How do we define what is ethical, moral and what is not? This type of moral theory merry-go-round proposes that we do not have any universal moral theory. We are judging A.I. on making decisions that may be immoral, but we should as well identify the fact that we are as immoral as A.I. We should definitely question and evaluate the decisions of an artificial intelligence, since it is the only way to bring more potentials out of it. The issue is not just about intrinsic or unintentional biases or dilemmas, but as well the explicit self-interests of big corporations. As the biggest developments are coming from those corporations, they would never bring innovations that do not serve their interests. Thus, any product brought by them I consider as biased.</p>
<p>In long term, assuming that we&rsquo;ll see the artificial general intelligence become reality, things get more interesting. Imagine one day we create an artificia super-intelligence that is self-aware and conscious. It&rsquo;s very probable that this artificial intelligence will be able itself create a higher intelligence than itself, which in turn would create yet another higher intelligence. This type of &lsquo;<a href="https://en.wikipedia.org/wiki/Technological_singularity" target="_blank" rel="noopener">intelligence explosion</a>&rsquo; may result into so called &ldquo;Singularity&rdquo;. Another look at it is by Bostrom, whose orthogonality thesis suggest that the utility (goal) of an A.I. is independent of any level of intelligence it has. It means that more intelligent A.I. does not automatically turn into an evil creature who wishes to extinct humanity. AGI employs its intelligence to achieve its goals.</p>
<p>It&rsquo;s hard to evaluate A.I., or at least I do find it hard. Main reason is because we are trying to assess a machine based on our anthropomorphic bias, in other words on our human-like characteristics, needs or goals. Even when we call it more intelligent, we assume that intelligence is one-dimensional, but it is not. For example Chimpanzees have way better short-term memory than humans. Assuming that short-term memory is an important part of intelligence, should we than claim that humans are less intelligent than them? It&rsquo;s non-sense, but I guess I could explain what I am thinking. Intelligence, ethics, or morals are not single dimensional and are evolving even among human civilizations through time. Comparing a machine intelligence based on what we know from ourselves is probably meaningless. Nonetheless, that does not mean that we should not look after it and try to predict how it will look like. What should A.I. maximize when it has to make decision? Whose preferences? Based on which dimensions?</p>

    </div>

    
        <div class="tags">
            
                <a href="https://heyhido.com/tags/philosophy">philosophy</a>
            
                <a href="https://heyhido.com/tags/machine-learning">machine-learning</a>
            
        </div>
    
    
    

</section>


    </main>
    
    <footer id="footer">
    
        <div id="social">


    <a class="symbol" href="https://github.com/hheydaroff" rel="me" target="_blank">
        
        <svg fill="#bbbbbb" width="28" height="28"  viewBox="0 0 72 72" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    
    <title>Github</title>
    <desc>Created with Sketch.</desc>
    <defs></defs>
    <g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="Social-Icons---Rounded-Black" transform="translate(-264.000000, -939.000000)">
            <g id="Github" transform="translate(264.000000, 939.000000)">
                <path d="M8,72 L64,72 C68.418278,72 72,68.418278 72,64 L72,8 C72,3.581722 68.418278,-8.11624501e-16 64,0 L8,0 C3.581722,8.11624501e-16 -5.41083001e-16,3.581722 0,8 L0,64 C5.41083001e-16,68.418278 3.581722,72 8,72 Z" id="Rounded" fill="#bbbbbb"></path>
                <path d="M35.9985,13 C22.746,13 12,23.7870921 12,37.096644 C12,47.7406712 18.876,56.7718301 28.4145,59.9584121 C29.6145,60.1797862 30.0525,59.4358488 30.0525,58.7973276 C30.0525,58.2250681 30.0315,56.7100863 30.0195,54.6996482 C23.343,56.1558981 21.9345,51.4693938 21.9345,51.4693938 C20.844,48.6864054 19.2705,47.9454799 19.2705,47.9454799 C17.091,46.4500754 19.4355,46.4801943 19.4355,46.4801943 C21.843,46.6503662 23.1105,48.9634994 23.1105,48.9634994 C25.2525,52.6455377 28.728,51.5823398 30.096,50.9649018 C30.3135,49.4077535 30.9345,48.3460615 31.62,47.7436831 C26.2905,47.1352808 20.688,45.0691228 20.688,35.8361671 C20.688,33.2052792 21.6225,31.0547881 23.1585,29.3696344 C22.911,28.7597262 22.0875,26.3110578 23.3925,22.9934585 C23.3925,22.9934585 25.4085,22.3459017 29.9925,25.4632101 C31.908,24.9285993 33.96,24.6620468 36.0015,24.6515052 C38.04,24.6620468 40.0935,24.9285993 42.0105,25.4632101 C46.5915,22.3459017 48.603,22.9934585 48.603,22.9934585 C49.9125,26.3110578 49.089,28.7597262 48.8415,29.3696344 C50.3805,31.0547881 51.309,33.2052792 51.309,35.8361671 C51.309,45.0917119 45.6975,47.1292571 40.3515,47.7256117 C41.2125,48.4695491 41.9805,49.9393525 41.9805,52.1877301 C41.9805,55.4089489 41.9505,58.0067059 41.9505,58.7973276 C41.9505,59.4418726 42.3825,60.1918338 43.6005,59.9554002 C53.13,56.7627944 60,47.7376593 60,37.096644 C60,23.7870921 49.254,13 35.9985,13" fill="#FFFFFF"></path>
            </g>
        </g>
    </g>
</svg>
    </a>

    <a class="symbol" href="https://www.linkedin.com/in/heyhido/" rel="me" target="_blank">
        
        <svg width="28" height="28" fill="#bbbbbb" viewBox="0 0 500 500">
  <g fill="none" fill-rule="evenodd">
    <rect width="500" height="500" fill="#bbbbbb" rx="50"/>
    <path fill="#FFF" d="M154.703 100.183c-19.121 0-34.689 15.565-34.703 34.701 0 19.136 15.568 34.704 34.703 34.704 19.128 0 34.688-15.568 34.688-34.704 0-19.134-15.561-34.701-34.688-34.701zm26.045 83.348h-52.094a4.488 4.488 0 0 0-4.488 4.489v167.675a4.488 4.488 0 0 0 4.488 4.488h52.093a4.49 4.49 0 0 0 4.489-4.488V188.02a4.486 4.486 0 0 0-4.488-4.489zm133.176-1.974c-19.064 0-35.817 5.805-46.04 15.271v-8.808c0-2.48-2.01-4.489-4.489-4.489h-49.971a4.489 4.489 0 0 0-4.489 4.489v167.675a4.488 4.488 0 0 0 4.489 4.488h52.044a4.49 4.49 0 0 0 4.489-4.488v-82.957c0-23.802 4.378-38.555 26.227-38.555 21.526.026 23.137 15.846 23.137 39.977v81.535a4.489 4.489 0 0 0 4.49 4.488h52.068a4.489 4.489 0 0 0 4.488-4.488v-91.977c-.001-38.253-7.553-82.161-66.443-82.161z"/>
  </g>
</svg>

    </a>

    <a class="symbol" href="https://twitter.com/heyhido" rel="me" target="_blank">
        
        <svg fill="#bbbbbb" width="28" height="28" version="1.1" id="Capa_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 width="438.536px" height="438.536px" viewBox="0 0 438.536 438.536" style="enable-background:new 0 0 438.536 438.536;"
	 xml:space="preserve">
<g>
	<path d="M414.41,24.123C398.333,8.042,378.963,0,356.315,0H82.228C59.58,0,40.21,8.042,24.126,24.123
		C8.045,40.207,0.003,59.576,0.003,82.225v274.084c0,22.647,8.042,42.018,24.123,58.102c16.084,16.084,35.454,24.126,58.102,24.126
		h274.084c22.648,0,42.018-8.042,58.095-24.126c16.084-16.084,24.126-35.454,24.126-58.102V82.225
		C438.532,59.576,430.49,40.204,414.41,24.123z M335.471,168.735c0.191,1.713,0.288,4.278,0.288,7.71
		c0,15.989-2.334,32.025-6.995,48.104c-4.661,16.087-11.8,31.504-21.416,46.254c-9.606,14.749-21.074,27.791-34.396,39.115
		c-13.325,11.32-29.311,20.365-47.968,27.117c-18.648,6.762-38.637,10.143-59.953,10.143c-33.116,0-63.76-8.952-91.931-26.836
		c4.568,0.568,9.329,0.855,14.275,0.855c27.6,0,52.439-8.565,74.519-25.7c-12.941-0.185-24.506-4.179-34.688-11.991
		c-10.185-7.803-17.273-17.699-21.271-29.691c4.947,0.76,8.658,1.137,11.132,1.137c4.187,0,9.042-0.76,14.56-2.279
		c-13.894-2.669-25.598-9.562-35.115-20.697c-9.519-11.136-14.277-23.84-14.277-38.114v-0.571
		c10.085,4.755,19.602,7.229,28.549,7.422c-17.321-11.613-25.981-28.265-25.981-49.963c0-10.66,2.758-20.747,8.278-30.264
		c15.035,18.464,33.311,33.213,54.816,44.252c21.507,11.038,44.54,17.227,69.092,18.558c-0.95-3.616-1.427-8.186-1.427-13.704
		c0-16.562,5.853-30.692,17.56-42.399c11.703-11.706,25.837-17.561,42.394-17.561c17.515,0,32.079,6.283,43.688,18.846
		c13.134-2.474,25.892-7.33,38.26-14.56c-4.757,14.652-13.613,25.788-26.55,33.402c12.368-1.716,23.88-4.95,34.537-9.708
		C357.458,149.793,347.462,160.166,335.471,168.735z"/>
</g>
</svg>

    </a>


</div>

    

    <div class="copyright">
    
        © Copyright 2023 ❤️ Hido
    
    </div>

    
      <div class="powerby">
        Powered by <a href='http://www.gohugo.io/'>Hugo</a> Theme By <a href='https://github.com/nodejh/hugo-theme-mini'>nodejh</a>
      </div>
    
</footer>



  </body>
</html>
